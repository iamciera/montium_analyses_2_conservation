## Make the database for alignmentKeys
con_db <- dbConnect(SQLite(), "../data/sql/TFBS_cons_DB.sqlite")
src_tbls(con_db)
dbDisconnect(con_db)
con_db <- DBI::dbConnect(RSQLite::SQLite(), "../data/sql/consScore.sqlite")
con_db <- DBI::dbConnect(RSQLite::SQLite(), "../data/sql/TFBS_cons_DB.sqlite")
src_tbls(test_db)
dbDisconnect(con_db)
dbListTables(con_db)
con_db <- DBI::dbConnect(RSQLite::SQLite(), "../data/sql/TFBS_cons_DB.sqlite")
dbListTables(con_db)
## List all the tables in the database
dbListTables(con_db)
dbWriteTable(con_db, name = "mostConserved", value = transform(most_conserved_align), row.names = FALSE, append = TRUE)
## List all the tables in the database
dbListTables(con_db)
# ## Test Database
#
consScore_SQL <- tbl(most_conserved, "mostConserved")
setwd("~/Desktop")
df1 <- read.csv("dataframe1.csv")
head(df1)
is.na(df1$pre_temp)
df1$pre_temp_present <- ifelse(is.na(df1$pre_temp)) = FALSE, 1, 0)
df1$pre_temp_present <- ifelse(is.na(df1$pre_temp)) = FALSE, 1, 0))
df1$pre_temp_present <- ifelse(is.na(df1$pre_temp)) = FALSE, "1", "0"))
is.na(df1$pre_temp)) = FALSE
df1$pre_temp_present <- ifelse(is.na(df1$pre_temp) = FALSE, "1", "0"))
df1$pre_temp_present <- ifelse(is.na(df1$pre_temp) = FALSE, "1", "0")
df1$pre_temp_present <- ifelse(is.na(df1$pre_temp) == FALSE, "1", "0")
head(df1)
df1$post_temp_present <- ifelse(is.na(df1$post_temp) == FALSE, "1", "0")
# Check
head(df1)
id <- df1$id
id <- df1$id[1:5,]
df1$id[1:5,]
## First Dataframe
df1 <- read.csv("dataframe1.csv")
df1$pre_temp_present <- ifelse(is.na(df1$pre_temp) == FALSE, "1", "0")
df1$post_temp_present <- ifelse(is.na(df1$post_temp) == FALSE, "1", "0")
# Check
head(df1)
id <- df1$id[1:5,]
id <- df1$id[1:5,]
id <- df1[1:5,]
id <- df1$id[1:5]
head(id)
visit_time <- df1$visit_time[1:5]
# Check
df1
pre_temp_present <- c(1,1,1,0,3)
post_temp_present<- c(1,1,1,1,3)
post_temp_present<- c(1,1,1,1,3)
df2<- cbind(id, visit_time, pre_temp_present)
df2
df2 <- as_data_frame(cbind(id, visit_time, pre_temp_present))
df2
df2 <- as.data.frame(cbind(id, visit_time, pre_temp_present))
df2
# Check
df1
df2
df2$post_temp_present <- c(1,1,1,1,3)
df2
df1$pre_temp_low <- ifelse(df1$pre_temp < 36.1, 1, 0)
x[findInterval(x, c(2,5)) == 1L] <- -1
df1$pre_temp_normal <- df1$pre_temp
replace(df1$pre_temp_normal, df1$pre_temp_normal < 38 & df1$pre_temp_normal > 36.1, 1)
df1$pre_temp_normal <- ifelse(( df1$pre_temp < 38 & df1$pre_temp > 36.1), 1, 0)
# Check
df1
df1$pre_temp_high <- ifelse(df1$pre_temp < 38, 1, 0)
# Check
df1
df1 <- df1[,-2]
# Check
df1
df2 <- df1
df2 <- df1
df2$pre_temp_low <- ifelse(df2$pre_temp < 36.1, 1, 0)
df2$pre_temp_normal <- ifelse(( df2$pre_temp < 38 & df2$pre_temp > 36.1), 1, 0)
df2$pre_temp_high <- ifelse(df2$pre_temp < 38, 1, 0)
# don't need visit_time
df2 <- df2[,-2]
df2
df2
# don't need pre_temp_present
df2 <- df2[,-3]
df2
df1
##################### DF1 done
df2 <- df1
df2$pre_temp_low <- ifelse(df2$pre_temp < 36.1, 1, 0)
df2$pre_temp_normal <- ifelse(( df2$pre_temp < 38 & df2$pre_temp > 36.1), 1, 0)
df2$pre_temp_high <- ifelse(df2$pre_temp < 38, 1, 0)
# don't need visit_time
df2 <- select(df2,-visit_time)
# don't need visit_time
df2 <- select(df2, -visit_time)
# don't need visit_time
df2 <- -select(df2, visit_time)
df2
df2 <- df1
df2
df2 <- df1
df2
# Check
df1
df1 <- read.csv("dataframe1.csv")
## not needed?
df1$pre_temp_present <- ifelse(is.na(df1$pre_temp) == FALSE, "1", "0")
df1$post_temp_present <- ifelse(is.na(df1$post_temp) == FALSE, "1", "0")
# Check
df1
df2 <- df1
df2$pre_temp_low <- ifelse(df2$pre_temp < 36.1, 1, 0)
df2$pre_temp_normal <- ifelse(( df2$pre_temp < 38 & df2$pre_temp > 36.1), 1, 0)
df2$pre_temp_high <- ifelse(df2$pre_temp < 38, 1, 0)
# don't need visit_time
df2 <- -select(df2, -visit_time)
df2
# don't need visit_time
df2 <- -df2[,-2]
df1 <- read.csv("dataframe1.csv")
## not needed?
df1$pre_temp_present <- ifelse(is.na(df1$pre_temp) == FALSE, "1", "0")
df1$post_temp_present <- ifelse(is.na(df1$post_temp) == FALSE, "1", "0")
# Check
df1
##################### DF1 done
df2 <- df1
df2$pre_temp_low <- ifelse(df2$pre_temp < 36.1, 1, 0)
df2$pre_temp_normal <- ifelse(( df2$pre_temp < 38 & df2$pre_temp > 36.1), 1, 0)
df2$pre_temp_high <- ifelse(df2$pre_temp < 38, 1, 0)
# don't need visit_time
df2 <- df2[,-2]
## Clean Data
## First Dataframe
df1 <- read.csv("dataframe1.csv")
## not needed?
df1$pre_temp_present <- ifelse(is.na(df1$pre_temp) == FALSE, "1", "0")
df1$post_temp_present <- ifelse(is.na(df1$post_temp) == FALSE, "1", "0")
# Check
df1
##################### DF1 done
df2 <- df1
df2$pre_temp_low <- ifelse(df2$pre_temp < 36.1, 1, 0)
df2$pre_temp_normal <- ifelse(( df2$pre_temp < 38 & df2$pre_temp > 36.1), 1, 0)
df2$pre_temp_high <- ifelse(df2$pre_temp < 38, 1, 0)
# don't need visit_time
df2 <- select(df2, -visit_time)
df2
# don't need visit_time
df2 <- select(df2, -c(visit_time, pre_temp_present, post_temp_present))
df2
df1 <- read.csv("dataframe1.csv")
## not needed?
df1$pre_temp_present <- ifelse(is.na(df1$pre_temp) == FALSE, "1", "0")
df1$post_temp_present <- ifelse(is.na(df1$post_temp) == FALSE, "1", "0")
# Check
df1
##################### DF1 done
df2 <- df1
df2$pre_temp_low <- ifelse(df2$pre_temp < 36.1, 1, 0)
df2$pre_temp_normal <- ifelse(( df2$pre_temp < 38 & df2$pre_temp > 36.1), 1, 0)
df2$pre_temp_high <- ifelse(df2$pre_temp < 38, 1, 0)
# don't need visit_time
df2 <- select(df2, -c(visit_time, pre_temp_present, post_temp_present))
df2
## First Dataframe
df1 <- read.csv("dataframe1.csv")
## not sure why these are needed, but here you go
df1$pre_temp_present <- ifelse(is.na(df1$pre_temp) == FALSE, "1", "0")
df1$post_temp_present <- ifelse(is.na(df1$post_temp) == FALSE, "1", "0")
# Check
df1
##################### DF1 done
df2 <- df1
df2$pre_temp_low <- ifelse(df2$pre_temp < 36.1, 1, 0)
df2$pre_temp_normal <- ifelse(( df2$pre_temp < 38 & df2$pre_temp > 36.1), 1, 0)
df2$pre_temp_high <- ifelse(df2$pre_temp > 38, 1, 0)
# don't need visit_time
df2 <- select(df2, -c(visit_time, pre_temp_present, post_temp_present))
df2
df2 <- df1
df2$pre_temp_low <- ifelse(df2$pre_temp < 36.1, 1, 0)
df2$pre_temp_normal <- ifelse(( df2$pre_temp < 38 & df2$pre_temp > 36.1), 1, 0)
df2$pre_temp_high <- ifelse(df2$pre_temp > 38, 1, 0)
# don't need visit_time
df2 <- select(df2, -visit_time)
df2
df2$post_temp_present <- c(1,1,1,1,3)
df2_dummy <- as.data.frame(cbind(id, visit_time, pre_temp_present))
df2_dummy$post_temp_present <- c(1,1,1,1,3)
df2_dummy$pre_temp_high
df2_dummy$pre_temp_loe <- NA
id <- df1$id[1:5]
visit_time <- df1$visit_time[1:5]
pre_temp_present <- c(1,1,1,0,3)
df2_dummy <- as.data.frame(cbind(id, visit_time, pre_temp_present))
df2_dummy$post_temp_present <- c(1,1,1,1,3)
df2_dummy$pre_temp_high <- NA
df2_dummy$pre_temp_normal <- NA
df2_dummy$pre_temp_low <- NA
head(df2_dummy)
df2_dummy
visit_time <- df1$visit_time[1:5]
visit_time
id <- df1$id[1:5]
visit_time <- df1$visit_time[1:5]
pre_temp_present <- c(1,1,1,0,3)
df2_dummy <- as.data.frame(cbind(id, visit_time, pre_temp_present))
df2_dummy
visit_time <- as.date(df1$visit_time[1:5])
id <- df1$id[1:5]
visit_time <- df1$visit_time[1:5]
pre_temp_present <- c(1,1,1,0,3)
df2_dummy <- as.data.frame(cbind(id, visit_time, pre_temp_present))
df2_dummy$post_temp_present <- c(1,1,1,1,3)
df2_dummy$pre_temp_high <- NA
df2_dummy$pre_temp_normal <- NA
df2_dummy$pre_temp_low <- NA
df2_dummy
as.data.frame(cbind(id, visit_time, pre_temp_present))
visit_time
##libraries
library(lubridate)
library(tidyverse)
df1
df1$visit_time <- mdy(df1$visit_time)
df1$visit_time
id <- df1$id[1:5]
visit_time <- df1$visit_time[1:5]
pre_temp_present <- c(1,1,1,0,3)
df2_dummy <- as.data.frame(cbind(id, visit_time, pre_temp_present))
df2_dummy
df2_dummy <- as.data.frame(cbind(id, mdy(visit_time), pre_temp_present))
visit_time <- mdy(df1$visit_time[1:5])
visit_time <- df1$visit_time[1:5]
visit_time
df2_dummy <- cbind(id, visit_time, pre_temp_present)
df2_dummy
df2_dummy <- as.data.frame(cbind(id, visit_time, pre_temp_present))
df2_dummy
visit_time
df2_dummy <- as.data.frame(id, visit_time, pre_temp_present)
id <- df1$id[1:5]
visit_time <- df1$visit_time[1:5])
pre_temp_present <- c(1,1,1,0,3)
df2_dummy <- as.data.frame(cbind(id, visit_time, pre_temp_present))
df2_dummy$post_temp_present <- c(1,1,1,1,3)
df2_dummy$pre_temp_high <- NA
df2_dummy$pre_temp_normal <- NA
df2_dummy$pre_temp_low <- NA
df2_dummy
df2
##libraries
library(lubridate)
library(tidyverse)
## First Dataframe
df1 <- read.csv("dataframe1.csv")
## set date with lubridate
df1$visit_time <- mdy(df1$visit_time)
## make first new columns
df1$pre_temp_present <- ifelse(is.na(df1$pre_temp) == FALSE, "1", "0")
df1$post_temp_present <- ifelse(is.na(df1$post_temp) == FALSE, "1", "0")
# Check
df1
##################### DF1 done
df2 <- df1
df2$pre_temp_low <- ifelse(df2$pre_temp < 36.1, 1, 0)
df2$pre_temp_normal <- ifelse(( df2$pre_temp < 38 & df2$pre_temp > 36.1), 1, 0)
df2$pre_temp_high <- ifelse(df2$pre_temp > 38, 1, 0)
df2
summarized_data <- ddply(df1, c("id"), summarise,
pre_temp_high    = sum(pre_temp_high),
pre_temp_normal = sum(pre_temp_normal),
pre_temp_present   = sum(pre_temp_present),
post_temp_present   = sum(post_temp_present))
library(ddplyr)
library( dplyr)
summarized_data <- ddply(df1, c("id"), summarise,
pre_temp_high    = sum(pre_temp_high),
pre_temp_normal = sum(pre_temp_normal),
pre_temp_present   = sum(pre_temp_present),
post_temp_present   = sum(post_temp_present))
library(dplyr2)
library(plyr)
summarized_data <- ddply(df1, c("id"), summarise,
pre_temp_high    = sum(pre_temp_high),
pre_temp_normal = sum(pre_temp_normal),
pre_temp_present   = sum(pre_temp_present),
post_temp_present   = sum(post_temp_present))
### remove pre_temp and post_temp
### YOu are going to have to summarize the information you by summing all
### occurances based on id, then look up those values and put into new dataframe
#### AND
### Keep only the first date, this is weird.
colnames(df1)
### remove pre_temp and post_temp
### YOu are going to have to summarize the information you by summing all
### occurances based on id, then look up those values and put into new dataframe
#### AND
### Keep only the first date, this is weird.
colnames(df1)
summarized_data <- ddply(df2, c("id"), summarise,
pre_temp_high    = sum(df1$pre_temp),
pre_temp_normal = sum(pre_temp_normal),
pre_temp_present   = sum(pre_temp_present),
post_temp_present   = sum(post_temp_present))
summarized_data <- ddply(df2, c("id"), summarise,
pre_temp_high    = sum(pre_temp_high),
pre_temp_normal = sum(pre_temp_normal),
pre_temp_present   = sum(pre_temp_present),
post_temp_present   = sum(post_temp_present))
summarized_data <- ddply(df2, c("id"), summarise,
pre_temp_high    = sum(pre_temp_high),
pre_temp_normal = sum(pre_temp_normal),
pre_temp_present   = sum(pre_temp_present, na.rm = TRUE),
post_temp_present   = sum(post_temp_present, na.rm = TRUE))
summarized_data <- ddply(df2, c("id"), summarise,
pre_temp_high    = sum(pre_temp_high, na.rm = TRUE),
pre_temp_normal = sum(pre_temp_normal, na.rm = TRUE),
pre_temp_present   = sum(pre_temp_present, na.rm = TRUE),
post_temp_present   = sum(post_temp_present, na.rm = TRUE))
## make first new columns
df1$pre_temp_present <- ifelse(is.na(df1$pre_temp) == FALSE, 1, 0)
df1$post_temp_present <- ifelse(is.na(df1$post_temp) == FALSE, 1, 0)
df2 <- df1
df2$pre_temp_low <- ifelse(df2$pre_temp < 36.1, 1, 0)
df2$pre_temp_normal <- ifelse(( df2$pre_temp < 38 & df2$pre_temp > 36.1), 1, 0)
df2$pre_temp_high <- ifelse(df2$pre_temp > 38, 1, 0)
### remove pre_temp and post_temp
### YOu are going to have to summarize the information you by summing all
### occurances based on id, then look up those values and put into new dataframe
#### AND
### Keep only the first date, this is weird.
colnames(df1)
summarized_data <- ddply(df2, c("id"), summarise,
pre_temp_high    = sum(pre_temp_high, na.rm = TRUE),
pre_temp_normal = sum(pre_temp_normal, na.rm = TRUE),
pre_temp_present   = sum(pre_temp_present, na.rm = TRUE),
post_temp_present   = sum(post_temp_present, na.rm = TRUE))
summarized_data <- ddply(df2, c("id"), summarise,
pre_temp_high    = sum(pre_temp_high, na.rm = TRUE),
pre_temp_normal = sum(pre_temp_normal, na.rm = TRUE),
pre_temp_present   = sum(pre_temp_present, na.rm = TRUE),
post_temp_present   = sum(post_temp_present, na.rm = TRUE))
summarized_data
summarized_data <- ddply(df2, c("id"), summarise,
pre_temp_high    = sum(pre_temp_high, na.rm = TRUE),
pre_temp_normal = sum(pre_temp_normal, na.rm = TRUE),
pre_temp_present   = sum(pre_temp_present, na.rm = TRUE),
post_temp_present   = sum(post_temp_present, na.rm = TRUE),
visit_time = visit_time)
summarized_data <- ddply(df2, c("id"), summarise,
pre_temp_high    = sum(pre_temp_high, na.rm = TRUE),
pre_temp_normal = sum(pre_temp_normal, na.rm = TRUE),
pre_temp_present   = sum(pre_temp_present, na.rm = TRUE),
post_temp_present   = sum(post_temp_present, na.rm = TRUE),
visit_time = visit_time[1])
summarized_data
df1
df2$visited <- 1
df3 <- ddply(df2, c("id"), summarise,
pre_temp_high    = sum(pre_temp_high, na.rm = TRUE),
pre_temp_normal = sum(pre_temp_normal, na.rm = TRUE),
pre_temp_present   = sum(pre_temp_present, na.rm = TRUE),
post_temp_present   = sum(post_temp_present, na.rm = TRUE),
visit_time = visit_time[1],
num_of_visits = sum(visited))
df3
df2
df3 <- ddply(df2, c("id"), summarise,
pre_temp_high    = sum(pre_temp_high, na.rm = TRUE),
pre_temp_normal = sum(pre_temp_normal, na.rm = TRUE),
pre_temp_low = sum(pre_temp_low, na.rm = TRUE),
pre_temp_present   = sum(pre_temp_present, na.rm = TRUE),
post_temp_present   = sum(post_temp_present, na.rm = TRUE),
visit_time = visit_time[1],
num_of_visits = sum(visited))
df3
ls
con_db <- DBI::dbConnect(RSQLite::SQLite(), "../data/sql/TFBS_cons_DB.sqlite")
setwd("~/Dropbox/Research2/montium_analyses_2_conservation/r")
con_db <- DBI::dbConnect(RSQLite::SQLite(), "../data/sql/TFBS_cons_DB.sqlite")
## List all the tables in the database
dbListTables(con_db)
## TFBS and Kvon expression data
## Takes ~4 min to load
TFBS_df <- read.csv("../data/outputs/combined_TFBS_kvon_13August2017.csv")
# This takes about 5 min
## Already Subsetted, but still 2.5GB
TFBS_df_0 <- read.table("../data/outputs/map_motif_output/all_map_motif_output_sub.csv", sep = "\t", header = FALSE)
install.packages("data.table")
library(data.table)
# This takes about 5 min
TFBS_df_0 <- read.table("../data/outputs/map_motif_output/map_motif_testoutput_everymotif.csv", sep = "\t", header = FALSE)
# This takes about 5 min
# There is no hunchback though, I have to go back and make hunchback with a smaller threshold level or somethingç
TFBS_df_0 <- fread("../data/outputs/map_motif_output/map_motif_testoutput_everymotif.csv", sep = "\t", header = FALSE)
# So not to have to read in again
TFBS_df <- TFBS_df_0
head(TFBS_df)
TFBS_df <- TFBS_df[,-1]
colnames(TFBS_df) <- c("position", "score",	"seq_len",	"species", "raw_position",	"strand",	"align_position",	"alignment_file", "motif_file")
## as.factor species
TFBS_df$species <- as.factor(TFBS_df$species)
test <- TFBS_df[1:100,]
head(test)
test <- test %>%
separate(species,
c("A", "B", "C", "D", "E", "F", "G"),
sep = "\\|", extra = "merge",
fill = "left") %>%
select(., -c(A:E, G))
head(test)
TFBS_df <- TFBS_df %>%
separate(species,
c("A", "B", "C", "D", "E", "F", "G"),
sep = "\\|", extra = "merge",
fill = "left") %>%
select(., -c(A:E, G))
test <- rename(test, species = F)
head(TFBS_df)
str(TFBS_df)
## Clean up alignment file notation
TFBS_df$alignment_file <- gsub("output_", "", TFBS_df$alignment_file)
TFBS_df$alignment_file <- gsub(".fa", "", TFBS_df$alignment_file)
head(TFBS)
head(TFBS_df)
colnames(TFBS_df)[4]
colnames(TFBS_df)[4] <- "species"
## Clean up motif_file
TFBS_df$motif_file <- gsub(".fm", "", TFBS_df$motif_file)
## Make prettier for graphs ahead of time
TFBS_df$strand <- gsub("positive", "+ strand", TFBS_df$strand, perl = TRUE)
TFBS_df$strand <- gsub("negative", "+ strand", TFBS_df$strand, perl = TRUE)
## Check
head(TFBS_df)
head(TFBS_df)
source('~/Dropbox/Research2/montium_analyses_2_conservation/r/mapMotif_sql_creation.R', echo=TRUE)
## Check
head(TFBS_df)
## Make the database for alignmentKeys
con_db <- dbConnect(SQLite(), "../data/sql/TFBS_cons_DB.sqlite")
dbWriteTable(con_db, name = "motifMap", value = transform(TFBS_df), row.names = FALSE, append = TRUE)
src_tables(con_db)
src_tbls(con_db)
## Make the database for alignmentKeys
con_db <- dbConnect(SQLite(), "../data/sql/TFBS_cons_DB.sqlite")
src_tbls(con_db)
dbDisconnect(con_db)
## Make the database for alignmentKeys
con_db <- dbConnect(SQLite(), "../data/sql/TFBS_cons_DB.sqlite")
src_tbls(con_db)
con_db <- DBI::dbConnect(RSQLite::SQLite(), "../data/sql/TFBS_cons_DB.sqlite")
## List all the tables in the database
dbListTables(con_db)
dbListTables(con_db)
dbDisconnect(con_db)
## Disconnect
dbDisconnect(con_db)
##### Test
levels(TFBS$species)
##### Test
levels(TFBS_df$species)
## Check
head(TFBS_df)
str(TFBS_df)
filter(TFBS_df, species %in% MEMB002A | motif_file %in% bcd_FlyReg)
filter(TFBS_df, species == MEMB002A | motif_file == bcd_FlyReg)
filter(TFBS_df, species == MEMB002A)
TFBS_subset <- subset(TFBS_df, species == "MEMB002A", motif_file == "bcd_FlyReg")
nrow(subset(TFBS_df, species == "MEMB002A", motif_file == "bcd_FlyReg"))
##### Test
head(TFBS_df)
nrow(subset(TFBS_df, species == "MEMB002A" & motif_file == "bcd_FlyReg"))
## Make the database for alignmentKeys
con_db <- dbConnect(SQLite(), "../data/sql/TFBS_cons_DB.sqlite")
motifMap_SQL <- tbl(con_db, "motifMap")
subset_after <- motifMap_SQL %>%
filter(species == "MEMB002A") %>%
filter(motif_file == "bcd_FlyReg")
subset_after
subset_after <- motifMap_SQL %>%
filter(species == "MEMB002A") %>%
filter(motif_file == "bcd_FlyReg")
collect()
## Disconnect
dbDisconnect(con_db)
## Make the database for alignmentKeys
con_db <- DBI::dbConnect(RSQLite::SQLite(), "../data/sql/TFBS_cons_DB.sqlite")
subset_after <- motifMap_SQL %>%
filter(species == "MEMB002A") %>%
filter(motif_file == "bcd_FlyReg")
collect()
subset_after <- motifMap_SQL %>%
filter(species == "MEMB002A") %>%
filter(motif_file == "bcd_FlyReg")
subset_after
motifMap_SQL <- tbl(con_db, "motifMap")
subset_after <- motifMap_SQL %>%
filter(species == "MEMB002A") %>%
filter(motif_file == "bcd_FlyReg")
nrow(subset_after)
subset_after <- motifMap_SQL %>%
filter(species == "MEMB002A") %>%
filter(motif_file == "bcd_FlyReg") %>%
collect()
nrow(subset_after)
